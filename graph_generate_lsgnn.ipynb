{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import warnings\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dataset_period = [datetime.strptime('2013-07-01', '%Y-%m-%d'), datetime.strptime('2017-10-01', '%Y-%m-%d')]\n",
    "test_period = [datetime.strptime('2017-10-01', '%Y-%m-%d') - timedelta(days=80), datetime.strptime('2017-10-01', '%Y-%m-%d')]\n",
    "valid_period = [test_period[0] - timedelta(days=40), test_period[0]]\n",
    "train_period = [dataset_period[0], valid_period[0]]\n",
    "predict_time = \"H\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_hdf('process_data_201306_201709/features.h5', key='features')\n",
    "station_info = pd.read_hdf('process_data_201306_201709/features.h5', key=\"info\")\n",
    "alive_df = pd.read_hdf('process_data_201306_201709/features.h5', key='alive')\n",
    "df_raw = pd.read_hdf('process_data_201306_201709/features.h5', key=\"raw\")\n",
    "df_raw['tripduration'] = (df_raw.stoptime - df_raw.starttime).dt.seconds\n",
    "df_raw.query('starttime >= @train_period[0] & stoptime < @train_period[1]', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "distance_graph = (\n",
    "    station_info[[\"stationid\", \"lat\", \"lon\"]]\n",
    "    .assign(merge_key=1)\n",
    ")\n",
    "distance_graph = distance_graph.merge(distance_graph, on=\"merge_key\").drop(\n",
    "    \"merge_key\", axis=1\n",
    ")\n",
    "distance_graph[\"distance\"] = distance_graph.apply(\n",
    "    lambda x: geodesic((x.lat_x, x.lon_x), (x.lat_y, x.lon_y)).meters, axis=1\n",
    ")\n",
    "distance_graph = distance_graph.pivot(\n",
    "    index=\"stationid_x\", columns=\"stationid_y\", values=\"distance\"\n",
    ")\n",
    "distance_graph = distance_graph ** -1\n",
    "\n",
    "for i in range(len(distance_graph)):\n",
    "    distance_graph.iloc[i,i] = 0\n",
    "\n",
    "distance_graph = distance_graph.replace([np.inf, -np.inf], np.nan)\n",
    "distance_graph = distance_graph.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rent Second Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "second_graph = (\n",
    "    df_raw[[\"startstationid\", \"endstationid\", \"tripduration\"]]\n",
    "    .groupby([\"startstationid\", \"endstationid\"], as_index=False)\n",
    "    .agg({\"tripduration\": np.median})\n",
    ")\n",
    "second_graph = second_graph.pivot(\n",
    "    index=\"startstationid\", columns=\"endstationid\", values=\"tripduration\"\n",
    ")\n",
    "second_graph = second_graph ** -1\n",
    "for i in range(len(second_graph)):\n",
    "    second_graph.iloc[i,i] = 0\n",
    "second_graph = second_graph.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "interaction_graph = (\n",
    "    df_raw[[\"startstationid\", \"endstationid\"]]\n",
    "    .groupby([\"startstationid\", \"endstationid\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"counts\")\n",
    ")\n",
    "interaction_graph = interaction_graph.pivot_table(\n",
    "    index=\"startstationid\", columns=\"endstationid\", values=\"counts\", fill_value=0\n",
    ")\n",
    "\n",
    "# caculate station alive size\n",
    "alive_size = alive_df.query('time >= @train_period[0] & time < @train_period[1] & is_alive == 1').groupby(['stationid'], as_index=False).size()\n",
    "alive_size = alive_size.pivot_table(\n",
    "    index=\"stationid\", columns=\"stationid\", values=\"size\", fill_value=0\n",
    ")\n",
    "alive_size = np.power(alive_size.values.astype(np.float32), -1)\n",
    "alive_size = np.where(np.isinf(alive_size), 0, alive_size)\n",
    "    \n",
    "# calulate mean hour interaction\n",
    "for i in range(len(interaction_graph)):\n",
    "    interaction_graph.iloc[i,i] = 0\n",
    "interaction_graph_out = pd.DataFrame(np.matmul(alive_size, interaction_graph.values), index=interaction_graph.index, columns=interaction_graph.columns)\n",
    "interaction_graph_in = pd.DataFrame(np.matmul(interaction_graph.values, alive_size), index=interaction_graph.index, columns=interaction_graph.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_graph = df_raw[[\"endstationid\", \"startstationid\", \"stoptime\", \"starttime\"]]\n",
    "correlation_graph = correlation_graph.assign(\n",
    "    stoptime=correlation_graph.stoptime.dt.floor(predict_time),\n",
    "    starttime=correlation_graph.starttime.dt.floor(predict_time),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "correlation_graph_in = (\n",
    "    correlation_graph.groupby([\"endstationid\", \"stoptime\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"flow_in\")\n",
    ")\n",
    "correlation_graph_in = correlation_graph_in.pivot_table(\n",
    "    index=\"stoptime\", columns=\"endstationid\", values=\"flow_in\", fill_value=0\n",
    ")\n",
    "correlation_graph_in = correlation_graph_in.corr(\"pearson\")\n",
    "for i in range(len(correlation_graph_in)):\n",
    "    correlation_graph_in.iloc[i,i] = 0\n",
    "correlation_graph_in_positive = correlation_graph_in.where(correlation_graph_in > 0, 0)\n",
    "correlation_graph_in_negative = correlation_graph_in.where(correlation_graph_in < 0, 0).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "correlation_graph_out = (\n",
    "    correlation_graph.groupby([\"startstationid\", \"starttime\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"flow_out\")\n",
    ")\n",
    "correlation_graph_out = correlation_graph_out.pivot_table(\n",
    "    index=\"starttime\", columns=\"startstationid\", values=\"flow_out\", fill_value=0\n",
    ")\n",
    "correlation_graph_out = correlation_graph_out.corr(\"pearson\")\n",
    "for i in range(len(correlation_graph_out)):\n",
    "    correlation_graph_out.iloc[i,i] = 0\n",
    "correlation_graph_out_positive = correlation_graph_out.where(correlation_graph_out > 0, 0)\n",
    "correlation_graph_out_negative = correlation_graph_out.where(correlation_graph_out < 0, 0).abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_norm(graph, axis):\n",
    "    deg = np.array(np.sum(graph, axis=axis))\n",
    "    deg = np.matrix(np.diag(deg)).astype(np.float32)\n",
    "    deg_inv = np.power(deg,-1)\n",
    "    deg_inv = np.where(np.isinf(deg_inv), 0, deg_inv)\n",
    "    A_norm = np.matmul(deg_inv, graph) + np.identity(graph.shape[0])\n",
    "    A_norm = torch.tensor(A_norm, dtype=torch.float32)\n",
    "    \n",
    "    return A_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_out = torch.stack([graph_norm(graph.values, 1) for graph in [distance_graph, second_graph, interaction_graph_out, correlation_graph_in_positive, correlation_graph_in_negative, correlation_graph_out_positive, correlation_graph_out_negative]])\n",
    "graph_in = torch.stack([graph_norm(graph.values, 0) for graph in [distance_graph, second_graph, interaction_graph_in, correlation_graph_in_positive, correlation_graph_in_negative, correlation_graph_out_positive, correlation_graph_out_negative]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Training Validation Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_num = len(station_info)\n",
    "train_len = ((features.time >= train_period[0]) & (features.time < train_period[1])).sum() // station_num\n",
    "val_len = ((features.time >= valid_period[0]) & (features.time < valid_period[1])).sum() // station_num\n",
    "test_len = ((features.time >= test_period[0]) & (features.time < test_period[1])).sum() // station_num\n",
    "print(f\"train length:{train_len}\\nvalidation length:{val_len}\\ntest length:{test_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = features.columns\n",
    "columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gcn_column = columns[columns.str.contains('|'.join(['bike', 'flow', 'gender', 'usertype', 'Hourly']))]\n",
    "print(len(gcn_column))\n",
    "gcn_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fc_column = columns[~columns.str.contains('|'.join(['flow','bike','stationid', 'time', \"y_in\", \"y_out\"]))]\n",
    "print(len(fc_column))\n",
    "fc_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = [\"y_in\", \"y_out\"]\n",
    "y_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = []\n",
    "for i in tqdm(np.arange(1, train_len + 1, 1)):\n",
    "    x = torch.tensor(\n",
    "        features.iloc[(i - 1) * station_num : i * station_num][gcn_column].values,\n",
    "        dtype=torch.float,\n",
    "    ).unsqueeze(0)\n",
    "    y = torch.tensor(\n",
    "        features.iloc[(i - 1) * station_num : i * station_num][y_column].values,\n",
    "        dtype=torch.float,\n",
    "    )\n",
    "    x_fc = torch.tensor(\n",
    "        features.iloc[(i - 1) * station_num : i * station_num][fc_column].values,\n",
    "        dtype=torch.float,\n",
    "    )\n",
    "    is_alive = torch.tensor(\n",
    "        alive_df.iloc[(i - 1) * station_num : i * station_num].is_alive.values,\n",
    "        dtype=torch.int8,\n",
    "    )\n",
    "    training_loader.append(\n",
    "        Data(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            x_fc=x_fc,\n",
    "            is_alive=is_alive,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loader = []\n",
    "for i in tqdm(np.arange(train_len + 1, train_len + val_len + 1, 1)):\n",
    "    x = torch.tensor(\n",
    "        features.iloc[(i - 1) * station_num : i * station_num][gcn_column].values,\n",
    "        dtype=torch.float,\n",
    "    ).unsqueeze(0)\n",
    "    y = torch.tensor(\n",
    "        features.iloc[(i - 1) * station_num : i * station_num][y_column].values,\n",
    "        dtype=torch.float,\n",
    "    )\n",
    "    x_fc = torch.tensor(\n",
    "        features.iloc[(i - 1) * station_num : i * station_num][fc_column].values,\n",
    "        dtype=torch.float,\n",
    "    )\n",
    "    is_alive = torch.tensor(\n",
    "        alive_df.iloc[(i - 1) * station_num : i * station_num].is_alive.values,\n",
    "        dtype=torch.int8,\n",
    "    )\n",
    "    validation_loader.append(\n",
    "        Data(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            x_fc=x_fc,\n",
    "            is_alive=is_alive,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_loader = []\n",
    "for i in tqdm(\n",
    "    np.arange(train_len + val_len + 1, train_len + val_len + test_len + 1, 1)\n",
    "):\n",
    "    x = torch.tensor(\n",
    "        features.iloc[(i - 1) * station_num : i * station_num][gcn_column].values,\n",
    "        dtype=torch.float,\n",
    "    ).unsqueeze(0)\n",
    "    \n",
    "    y = torch.tensor(\n",
    "        features.iloc[(i - 1) * station_num : i * station_num][y_column].values,\n",
    "        dtype=torch.float,\n",
    "    )\n",
    "    x_fc = torch.tensor(\n",
    "        features.iloc[(i - 1) * station_num : i * station_num][fc_column].values,\n",
    "        dtype=torch.float,\n",
    "    )\n",
    "    is_alive = torch.tensor(\n",
    "        alive_df.iloc[(i - 1) * station_num : i * station_num].is_alive.values,\n",
    "        dtype=torch.int8,\n",
    "    )\n",
    "    testing_loader.append(\n",
    "        Data(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            x_fc=x_fc,\n",
    "            is_alive=is_alive,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(\n",
    "    {\n",
    "        'training_loader':training_loader,\n",
    "        'validation_loader':validation_loader,\n",
    "        'testing_loader':testing_loader,\n",
    "        'graph_in':graph_in,\n",
    "        'graph_out':graph_out,\n",
    "    },\n",
    "    'process_data/loader_lsgnn_simple.pt'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_bike",
   "language": "python",
   "name": "gnn_bike"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
